{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10a2eeb6-3f27-4e58-877a-661b03ae3611",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "n:\\work\\japanese_stablelm_base\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:NNCF initialized successfully. Supported frameworks detected: torch, onnx, openvino\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n        input_ids: Optional[torch.LongTensor] = None,\\n        attention_mask: Optional[torch.FloatTensor] = None,\\n        position_ids: Optional[torch.LongTensor] = None,\\n        inputs_embeds: Optional[torch.FloatTensor] = None,\\n        head_mask: Optional[torch.FloatTensor] = None,\\n        past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\\n        labels: Optional[torch.LongTensor] = None,\\n        use_cache: Optional[bool] = None,\\n        output_attentions: Optional[bool] = N}one,\\n        output_hidden_states: Optional[bool] = None,\\n        return_dict: Optional[bool] = None,\\n    ) -> Union[Tuple, CausalLMOutputWithPast]:\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM\n",
    "import openvino as ov\n",
    "from nncf import compress_weights, CompressWeightsMode\n",
    "import nncf\n",
    "import torch\n",
    "\n",
    "#model_id = 'stabilityai/japanese-stablelm-base-alpha-7b'\n",
    "model_id = 'stabilityai/japanese-stablelm-base-gamma-7b'\n",
    "model_vendor, model_name = model_id.split('/') \n",
    "\n",
    "\"\"\"\n",
    "        input_ids: Optional[torch.LongTensor] = None,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = N}one,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple, CausalLMOutputWithPast]:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22525010-7115-4825-924d-47d524ce00b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.82s/it]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(f'{model_vendor}/{model_name}', trust_remote_code=True)\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dac5745-7847-476b-bd72-ad099dfd3755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MistralForCausalLM(\n",
      "  (model): MistralModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x MistralDecoderLayer(\n",
      "        (self_attn): MistralSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): MistralRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): MistralMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): MistralRMSNorm()\n",
      "        (post_attention_layernorm): MistralRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): MistralRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c7eadb3-63f6-4a49-a3b5-c8f9565078e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "2\n",
      "torch.Size([1, 8, 0, 128])\n",
      "tensor([[808, 758,  50, 368, 847,  62, 847, 961, 659, 915]], dtype=torch.int32) tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=torch.int32) tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "num_seq = 10\n",
    "# from config.json\n",
    "vocab_size = 32000\n",
    "hidden_size = 4096\n",
    "num_hidden_layers = 8   # alpha=32, gamma=8\n",
    "num_attention_heads = 32\n",
    "\n",
    "#past_kv = torch.Tensor(size=(1, num_attention_heads, 1, hidden_size // num_hidden_layers))\n",
    "past_kv = torch.Tensor(size=(1, num_hidden_layers, 0, 128))\n",
    "past_key_values = tuple([(past_kv, past_kv) for _ in range(num_attention_heads)])\n",
    "#past_key_values = torch.Tensor(size=(32,2,1,num_hidden_layers,1,128))\n",
    "print(len(past_key_values))\n",
    "print(len(past_key_values[0]))\n",
    "print(past_key_values[0][0].shape)\n",
    "\n",
    "\n",
    "import random\n",
    "n = 10\n",
    "example_input = {\n",
    "    'input_ids'     : torch.tensor([[ random.randint(5, 1000)  for _ in range(n)]], dtype=torch.int),\n",
    "    'attention_mask': torch.tensor([[ 1]*n], dtype=torch.int),\n",
    "    'position_ids'  : torch.tensor([[ nn for nn in range(0, n)]], dtype=torch.int),\n",
    "    #'inputs_embeds': np.array([0], dtype=np.int32),\n",
    "    # input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\n",
    "    #'head_mask': torch.Tensor(size=(num_attention_heads,1,1,1,n)).to(torch.float32),\n",
    "\n",
    "    'past_key_values' : past_key_values,\n",
    "    #'past_key_values': torch.Tensor(size=(num_hidden_layers, 2, 1, num_attention_heads, num_seq, hidden_size // num_hidden_layers)).to(torch.float32),\n",
    "    #'past_key_values': torch.Tensor(size=(1, 2, 1, num_attention_heads, num_seq, hidden_size // num_hidden_layers)).to(torch.float32),\n",
    "    #  past_key_values [n][0|1][ 1, 32, seq_len, 128]       # alpha\n",
    "    #  past_key_values [n][0|1][ 1, 8, seq_len, 128]       # gamma\n",
    "\n",
    "    #'labels': np.zeros((1,100), dtype=np.int32),\n",
    "    'use_cache'           : torch.tensor( True, dtype=torch.bool),\n",
    "    'output_attentions'   : torch.tensor(False, dtype=torch.bool),\n",
    "    'output_hidden_states': torch.tensor(False, dtype=torch.bool),\n",
    "    'return_dict'         : torch.tensor(False, dtype=torch.bool),\n",
    "}\n",
    "\n",
    "print(example_input['input_ids'], example_input['attention_mask'], example_input['position_ids'])\n",
    "#print(example_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1236d17d-fc34-4a72-b76b-3025ef38ce58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Model: 'Model4'\n",
      "inputs[\n",
      "<ConstOutput: names[input_ids] shape[?,?] type: i32>,\n",
      "<ConstOutput: names[attention_mask] shape[?,?] type: i32>,\n",
      "<ConstOutput: names[position_ids] shape[?,?] type: i32>,\n",
      "<ConstOutput: names[42, key_states.1] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[43] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[44] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[45] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[46] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[47] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[48] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[49] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[50] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[51] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[52] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[53] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[54] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[55] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[56] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[57] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[58] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[59] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[60] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[61] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[62] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[63] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[64] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[65] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[66] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[67] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[68] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[69] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[70] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[71] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[72] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[73] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[74] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[75] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[76] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[77] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[78] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[79] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[80] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[81] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[82] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[83] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[84] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[85] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[86] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[87] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[88] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[89] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[90] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[91] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[92] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[93] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[94] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[95] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[96] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[97] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[98] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[99] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[100] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[101] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[102] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[103] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[104] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[105] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[use_cache] shape[] type: boolean>,\n",
      "<ConstOutput: names[output_attentions] shape[] type: boolean>,\n",
      "<ConstOutput: names[output_hidden_states] shape[] type: boolean>,\n",
      "<ConstOutput: names[return_dict] shape[] type: boolean>\n",
      "]\n",
      "outputs[\n",
      "<ConstOutput: names[5869, logits, 5870, 171] shape[?,?,32000] type: f32>,\n",
      "<ConstOutput: names[107, 446, 5804, hidden_states.11, 520, 490] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[5805, 448, hidden_states.15, 521, 491, 108] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[5806, 616, hidden_states.41, 109, 660, 690] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[618, hidden_states.45, 661, 691, 110, 5807] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[830, 786, hidden_states.71, 860, 5808, 111] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[861, 788, hidden_states.75, 112, 831, 5809] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[1030, 956, hidden_states.101, 113, 1000, 5810] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[114, 958, 5811, hidden_states.105, 1001, 1031] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[5812, 1126, hidden_states.131, 1170, 1200, 115] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[1201, 1128, hidden_states.135, 116, 1171, 5813] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[5814, 1296, 117, hidden_states.161, 1340, 1370] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[1298, hidden_states.165, 1341, 118, 1371, 5815] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[1466, 5816, 1540, hidden_states.191, 119, 1510] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[120, 1468, hidden_states.195, 1511, 5817, 1541] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[1636, 121, 5818, hidden_states.221, 1680, 1710] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[1638, hidden_states.225, 1681, 1711, 5819, 122] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[1806, hidden_states.251, 1850, 1880, 5820, 123] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[1808, 124, hidden_states.255, 1851, 1881, 5821] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[2050, 1976, hidden_states.281, 125, 2020, 5822] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[1978, hidden_states.285, 2021, 2051, 5823, 126] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[2146, hidden_states.311, 2190, 127, 2220, 5824] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[2148, hidden_states.315, 2191, 2221, 5825, 128] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[2316, 5826, hidden_states.341, 2360, 2390, 129] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[5827, 2318, hidden_states.345, 130, 2361, 2391] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[2486, 2530, hidden_states.371, 2560, 5828, 131] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[2488, hidden_states.375, 2531, 2561, 132, 5829] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[2700, 2656, hidden_states.401, 2730, 5830, 133] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[2658, hidden_states.405, 2701, 2731, 5831, 134] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[2826, hidden_states.431, 135, 2870, 2900, 5832] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[2828, 5833, hidden_states.435, 2871, 2901, 136] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[2996, hidden_states.461, 3040, 3070, 5834, 137] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[3041, 2998, 138, hidden_states.465, 3071, 5835] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[3210, 3166, 139, 3240, hidden_states.491, 5836] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[3241, 3168, 140, hidden_states.495, 3211, 5837] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[3336, hidden_states.521, 141, 5838, 3410, 3380] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[5839, 3411, 3381, 3338, hidden_states.525, 142] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[3506, hidden_states.551, 3550, 3580, 5840, 143] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[3508, 3551, hidden_states.555, 3581, 5841, 144] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[3720, 3676, hidden_states.581, 5842, 3750, 145] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[3678, 146, 3721, hidden_states.585, 5843, 3751] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[5844, 3846, hidden_states.611, 3890, 3920, 147] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[3848, hidden_states.615, 3891, 148, 3921, 5845] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[4016, 4060, hidden_states.641, 4090, 5846, 149] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[4018, 4091, hidden_states.645, 4061, 150, 5847] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[5848, 4186, hidden_states.671, 4230, 4260, 151] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[4188, hidden_states.675, 152, 4231, 4261, 5849] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[4356, 153, hidden_states.701, 5850, 4400, 4430] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[154, 4358, hidden_states.705, 5851, 4401, 4431] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[155, 4526, hidden_states.731, 4570, 5852, 4600] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[4528, 156, hidden_states.735, 4571, 5853, 4601] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[157, 4696, hidden_states.761, 4740, 4770, 5854] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[5855, 4698, hidden_states.765, 4741, 4771, 158] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[4866, hidden_states.791, 4910, 4940, 5856, 159] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[4868, hidden_states.795, 4911, 4941, 5857, 160] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[161, 5858, 5036, hidden_states.821, 5080, 5110] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[5081, 5038, hidden_states.825, 5111, 5859, 162] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[5206, hidden_states.851, 5250, 5860, 5280, 163] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[164, 5208, 5251, hidden_states.855, 5861, 5281] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[5376, hidden_states.881, 5420, 165, 5450, 5862] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[5451, 5378, 5421, hidden_states.885, 5863, 166] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[5546, hidden_states.911, 5590, 5620, 5864, 167] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[5621, 5548, hidden_states.915, 5591, 5865, 168] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[5716, hidden_states.941, 5760, 5866, 5790, 169] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[5718, hidden_states.945, 5761, 5867, 5791, 170] shape[?,8,?,128] type: f32>\n",
      "]>\n"
     ]
    }
   ],
   "source": [
    "ov_model = ov.convert_model(model, example_input=example_input)\n",
    "print(ov_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7c3e186-dc37-436d-bb9e-b289ba23193c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "n:\\work\\japanese_stablelm_base\\venv\\lib\\site-packages\\nncf\\quantization\\quantize_model.py:292: FutureWarning: `CompressWeightsMode.INT8` is deprecated.Please, use `CompressWeightsMode.INT8_ASYM` as value instead.\n",
      "  warning_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:Statistics of the bitwidth distribution:\n",
      "+--------------+---------------------------+-----------------------------------+\n",
      "| Num bits (N) | % all parameters (layers) |    % ratio-defining parameters    |\n",
      "|              |                           |             (layers)              |\n",
      "+==============+===========================+===================================+\n",
      "| 8            | 100% (226 / 226)          | 100% (226 / 226)                  |\n",
      "+--------------+---------------------------+-----------------------------------+\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">n:\\work\\japanese_stablelm_base\\venv\\lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "n:\\work\\japanese_stablelm_base\\venv\\lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compressed_model = compress_weights(ov_model, mode=CompressWeightsMode.INT8)\n",
    "ov.save_model(compressed_model, 'openvino_model_int8.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b0255e1-3fbf-42d7-a105-6dd3e9b13d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:Statistics of the bitwidth distribution:\n",
      "+--------------+---------------------------+-----------------------------------+\n",
      "| Num bits (N) | % all parameters (layers) |    % ratio-defining parameters    |\n",
      "|              |                           |             (layers)              |\n",
      "+==============+===========================+===================================+\n",
      "| 8            | 4% (2 / 226)              | 0% (0 / 224)                      |\n",
      "+--------------+---------------------------+-----------------------------------+\n",
      "| 4            | 96% (224 / 226)           | 100% (224 / 224)                  |\n",
      "+--------------+---------------------------+-----------------------------------+\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compressed_model = compress_weights(ov_model, mode=CompressWeightsMode.INT4_ASYM)\n",
    "ov.save_model(compressed_model, 'openvino_model_int4asym.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2774c61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
