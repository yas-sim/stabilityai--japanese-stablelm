{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10a2eeb6-3f27-4e58-877a-661b03ae3611",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:NNCF initialized successfully. Supported frameworks detected: torch, tensorflow, onnx, openvino\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM\n",
    "import openvino as ov\n",
    "from nncf import compress_weights, CompressWeightsMode\n",
    "import nncf\n",
    "import torch\n",
    "\n",
    "#model_id = 'stabilityai/japanese-stablelm-base-alpha-7b'\n",
    "model_id = 'stabilityai/japanese-stablelm-base-gamma-7b'\n",
    "model_vendor, model_name = model_id.split('/') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364aea60-7391-4ecc-ad93-7363e3f18e58",
   "metadata": {},
   "source": [
    "## Load (or download) the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22525010-7115-4825-924d-47d524ce00b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7687d90c5794b4da69bb08eec5c0f14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralSdpaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(f'{model_vendor}/{model_name}', trust_remote_code=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1282a8fd-175d-4aec-a302-5cfc73c62a1b",
   "metadata": {},
   "source": [
    "## Define '`example_input`' for model conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c7eadb3-63f6-4a49-a3b5-c8f9565078e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_seq = 10\n",
    "# from config.json\n",
    "vocab_size = 32000\n",
    "hidden_size = 4096\n",
    "num_hidden_layers = 32\n",
    "num_attention_heads = 32\n",
    "num_key_value_heads = 8\n",
    "\n",
    "past_kv = torch.Tensor(size=(1, num_key_value_heads, 0, hidden_size // num_hidden_layers))\n",
    "past_key_values = tuple([(past_kv, past_kv) for _ in range(num_hidden_layers)])\n",
    "\n",
    "example_input = {\n",
    "    'input_ids'     : torch.tensor([[ 123 for _ in range(num_seq)]], dtype=torch.int),\n",
    "    'attention_mask': torch.tensor([[ 1] * num_seq], dtype=torch.int),\n",
    "    'position_ids'  : torch.tensor([[ nn for nn in range(num_seq)]], dtype=torch.int),\n",
    "    #'inputs_embeds': np.array([0], dtype=np.int32),\n",
    "    # input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\n",
    "    #'head_mask': torch.Tensor(size=(num_attention_heads,1,1,1,n)).to(torch.float32),\n",
    "\n",
    "    'past_key_values' : past_key_values,\n",
    "    #  past_key_values [n][0|1][ 1, 32, seq_len, 128]       # alpha\n",
    "    #  past_key_values [n][0|1][ 1, 8, seq_len, 128]        # gamma\n",
    "\n",
    "    #'labels': np.zeros((1,100), dtype=np.int32),\n",
    "    'use_cache'           : torch.tensor( True, dtype=torch.bool),\n",
    "    'output_attentions'   : torch.tensor(False, dtype=torch.bool),\n",
    "    'output_hidden_states': torch.tensor(False, dtype=torch.bool),\n",
    "    'return_dict'         : torch.tensor(False, dtype=torch.bool),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6898f3ec-ab29-48e5-9ffe-1dc83283f694",
   "metadata": {},
   "source": [
    "## Convert the model into OpenVINO IR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1236d17d-fc34-4a72-b76b-3025ef38ce58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:nncf:NNCF provides best results with torch==2.1.2, while current torch version is 2.2.1+cpu. If you encounter issues, consider switching to torch==2.1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "N:\\work\\venv-ov23.3\\lib\\site-packages\\transformers\\modeling_utils.py:4193: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
      "  warnings.warn(\n",
      "N:\\work\\venv-ov23.3\\lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:971: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if use_cache:\n",
      "N:\\work\\venv-ov23.3\\lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:1001: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  elif self._attn_implementation == \"sdpa\" and not output_attentions:\n",
      "N:\\work\\venv-ov23.3\\lib\\site-packages\\transformers\\modeling_attn_mask_utils.py:114: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if (input_shape[-1] > 1 or self.sliding_window is not None) and self.is_causal:\n",
      "N:\\work\\venv-ov23.3\\lib\\site-packages\\transformers\\modeling_attn_mask_utils.py:162: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if past_key_values_length > 0:\n",
      "N:\\work\\venv-ov23.3\\lib\\site-packages\\transformers\\modeling_attn_mask_utils.py:411: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if query_length > 1 and not is_tracing:\n",
      "N:\\work\\venv-ov23.3\\lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:1023: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  all_hidden_states = () if output_hidden_states else None\n",
      "N:\\work\\venv-ov23.3\\lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:1024: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  all_self_attns = () if output_attentions else None\n",
      "N:\\work\\venv-ov23.3\\lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:1028: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if output_hidden_states:\n",
      "N:\\work\\venv-ov23.3\\lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:636: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if output_attentions:\n",
      "N:\\work\\venv-ov23.3\\lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:120: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if seq_len > self.max_seq_len_cached:\n",
      "N:\\work\\venv-ov23.3\\lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:676: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if attention_mask.size() != (bsz, 1, q_len, kv_seq_len):\n",
      "N:\\work\\venv-ov23.3\\lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:775: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if output_attentions:\n",
      "N:\\work\\venv-ov23.3\\lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:778: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if use_cache:\n",
      "N:\\work\\venv-ov23.3\\lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:1053: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if use_cache:\n",
      "N:\\work\\venv-ov23.3\\lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:1054: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  next_decoder_cache = layer_outputs[2 if output_attentions else 1]\n",
      "N:\\work\\venv-ov23.3\\lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:1056: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if output_attentions:\n",
      "N:\\work\\venv-ov23.3\\lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:1062: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if output_hidden_states:\n",
      "N:\\work\\venv-ov23.3\\lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:1066: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if use_cache:\n",
      "N:\\work\\venv-ov23.3\\lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:1069: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if not return_dict:\n",
      "N:\\work\\venv-ov23.3\\lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:1186: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if not return_dict:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Model: 'Model0'\n",
      "inputs[\n",
      "<ConstOutput: names[input_ids] shape[?,?] type: i32>,\n",
      "<ConstOutput: names[attention_mask] shape[?,?] type: i32>,\n",
      "<ConstOutput: names[position_ids] shape[?,?] type: i32>,\n",
      "<ConstOutput: names[42, key_states.1] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[43] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[44] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[45] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[46] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[47] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[48] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[49] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[50] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[51] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[52] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[53] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[54] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[55] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[56] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[57] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[58] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[59] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[60] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[61] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[62] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[63] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[64] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[65] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[66] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[67] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[68] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[69] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[70] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[71] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[72] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[73] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[74] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[75] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[76] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[77] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[78] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[79] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[80] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[81] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[82] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[83] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[84] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[85] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[86] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[87] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[88] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[89] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[90] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[91] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[92] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[93] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[94] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[95] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[96] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[97] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[98] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[99] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[100] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[101] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[102] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[103] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[104] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[105] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[use_cache] shape[] type: boolean>,\n",
      "<ConstOutput: names[output_attentions] shape[] type: boolean>,\n",
      "<ConstOutput: names[output_hidden_states] shape[] type: boolean>,\n",
      "<ConstOutput: names[return_dict] shape[] type: boolean>\n",
      "]\n",
      "outputs[\n",
      "<ConstOutput: names[5869, logits, 5870, 171] shape[?,?,32000] type: f32>,\n",
      "<ConstOutput: names[107, 446, 5804, hidden_states.11, 520, 490] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[5805, 448, hidden_states.15, 521, 491, 108] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[5806, 616, hidden_states.41, 109, 660, 690] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[618, hidden_states.45, 661, 691, 110, 5807] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[830, 786, hidden_states.71, 860, 5808, 111] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[861, 788, hidden_states.75, 112, 831, 5809] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[1030, 956, hidden_states.101, 113, 1000, 5810] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[114, 958, 5811, hidden_states.105, 1001, 1031] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[5812, 1126, hidden_states.131, 1170, 1200, 115] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[1201, 1128, hidden_states.135, 116, 1171, 5813] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[5814, 1296, 117, hidden_states.161, 1340, 1370] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[1298, hidden_states.165, 1341, 118, 1371, 5815] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[1466, 5816, 1540, hidden_states.191, 119, 1510] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[120, 1468, hidden_states.195, 1511, 5817, 1541] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[1636, 121, 5818, hidden_states.221, 1680, 1710] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[1638, hidden_states.225, 1681, 1711, 5819, 122] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[1806, hidden_states.251, 1850, 1880, 5820, 123] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[1808, 124, hidden_states.255, 1851, 1881, 5821] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[2050, 1976, hidden_states.281, 125, 2020, 5822] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[1978, hidden_states.285, 2021, 2051, 5823, 126] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[2146, hidden_states.311, 2190, 127, 2220, 5824] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[2148, hidden_states.315, 2191, 2221, 5825, 128] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[2316, 5826, hidden_states.341, 2360, 2390, 129] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[5827, 2318, hidden_states.345, 130, 2361, 2391] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[2486, 2530, hidden_states.371, 2560, 5828, 131] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[2488, hidden_states.375, 2531, 2561, 132, 5829] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[2700, 2656, hidden_states.401, 2730, 5830, 133] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[2658, hidden_states.405, 2701, 2731, 5831, 134] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[2826, hidden_states.431, 135, 2870, 2900, 5832] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[2828, 5833, hidden_states.435, 2871, 2901, 136] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[2996, hidden_states.461, 3040, 3070, 5834, 137] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[3041, 2998, 138, hidden_states.465, 3071, 5835] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[3210, 3166, 139, 3240, hidden_states.491, 5836] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[3241, 3168, 140, hidden_states.495, 3211, 5837] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[3336, hidden_states.521, 141, 5838, 3410, 3380] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[5839, 3411, 3381, 3338, hidden_states.525, 142] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[3506, hidden_states.551, 3550, 3580, 5840, 143] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[3508, 3551, hidden_states.555, 3581, 5841, 144] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[3720, 3676, hidden_states.581, 5842, 3750, 145] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[3678, 146, 3721, hidden_states.585, 5843, 3751] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[5844, 3846, hidden_states.611, 3890, 3920, 147] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[3848, hidden_states.615, 3891, 148, 3921, 5845] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[4016, 4060, hidden_states.641, 4090, 5846, 149] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[4018, 4091, hidden_states.645, 4061, 150, 5847] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[5848, 4186, hidden_states.671, 4230, 4260, 151] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[4188, hidden_states.675, 152, 4231, 4261, 5849] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[4356, 153, hidden_states.701, 5850, 4400, 4430] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[154, 4358, hidden_states.705, 5851, 4401, 4431] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[155, 4526, hidden_states.731, 4570, 5852, 4600] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[4528, 156, hidden_states.735, 4571, 5853, 4601] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[157, 4696, hidden_states.761, 4740, 4770, 5854] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[5855, 4698, hidden_states.765, 4741, 4771, 158] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[4866, hidden_states.791, 4910, 4940, 5856, 159] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[4868, hidden_states.795, 4911, 4941, 5857, 160] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[161, 5858, 5036, hidden_states.821, 5080, 5110] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[5081, 5038, hidden_states.825, 5111, 5859, 162] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[5206, hidden_states.851, 5250, 5860, 5280, 163] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[164, 5208, 5251, hidden_states.855, 5861, 5281] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[5376, hidden_states.881, 5420, 165, 5450, 5862] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[5451, 5378, 5421, hidden_states.885, 5863, 166] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[5546, hidden_states.911, 5590, 5620, 5864, 167] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[5621, 5548, hidden_states.915, 5591, 5865, 168] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[5716, hidden_states.941, 5760, 5866, 5790, 169] shape[?,8,?,128] type: f32>,\n",
      "<ConstOutput: names[5718, hidden_states.945, 5761, 5867, 5791, 170] shape[?,8,?,128] type: f32>\n",
      "]>\n"
     ]
    }
   ],
   "source": [
    "ov_model = ov.convert_model(model, example_input=example_input)\n",
    "print(ov_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7c3e186-dc37-436d-bb9e-b289ba23193c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "N:\\work\\venv-ov23.3\\lib\\site-packages\\nncf\\quantization\\quantize_model.py:292: FutureWarning: `CompressWeightsMode.INT8` is deprecated.Please, use `CompressWeightsMode.INT8_ASYM` as value instead.\n",
      "  warning_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:Statistics of the bitwidth distribution:\n",
      "+--------------+---------------------------+-----------------------------------+\n",
      "| Num bits (N) | % all parameters (layers) |    % ratio-defining parameters    |\n",
      "|              |                           |             (layers)              |\n",
      "+==============+===========================+===================================+\n",
      "| 8            | 100% (226 / 226)          | 100% (226 / 226)                  |\n",
      "+--------------+---------------------------+-----------------------------------+\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc50ee6c5b30414081b4e909f64b8750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compressed_model = compress_weights(ov_model.clone(), mode=CompressWeightsMode.INT8)\n",
    "ov.save_model(compressed_model, 'openvino_model_int8.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b0255e1-3fbf-42d7-a105-6dd3e9b13d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:Statistics of the bitwidth distribution:\n",
      "+--------------+---------------------------+-----------------------------------+\n",
      "| Num bits (N) | % all parameters (layers) |    % ratio-defining parameters    |\n",
      "|              |                           |             (layers)              |\n",
      "+==============+===========================+===================================+\n",
      "| 8            | 4% (2 / 226)              | 0% (0 / 224)                      |\n",
      "+--------------+---------------------------+-----------------------------------+\n",
      "| 4            | 96% (224 / 226)           | 100% (224 / 224)                  |\n",
      "+--------------+---------------------------+-----------------------------------+\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1354589851624e73b340f8d595beef18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compressed_model = compress_weights(ov_model.clone(), mode=CompressWeightsMode.INT4_ASYM)\n",
    "ov.save_model(compressed_model, 'openvino_model_int4asym.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1b56c2-224d-49c0-922d-20c30e2aa620",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
