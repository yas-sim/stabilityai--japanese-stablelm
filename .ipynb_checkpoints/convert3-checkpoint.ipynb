{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10a2eeb6-3f27-4e58-877a-661b03ae3611",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n        input_ids: Optional[torch.LongTensor] = None,\\n        attention_mask: Optional[torch.FloatTensor] = None,\\n        position_ids: Optional[torch.LongTensor] = None,\\n        inputs_embeds: Optional[torch.FloatTensor] = None,\\n        head_mask: Optional[torch.FloatTensor] = None,\\n        past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\\n        labels: Optional[torch.LongTensor] = None,\\n        use_cache: Optional[bool] = None,\\n        output_attentions: Optional[bool] = None,\\n        output_hidden_states: Optional[bool] = None,\\n        return_dict: Optional[bool] = None,\\n    ) -> Union[Tuple, CausalLMOutputWithPast]:\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM\n",
    "import openvino as ov\n",
    "\n",
    "import torch\n",
    "\n",
    "model_vendor, model_name = 'stabilityai', 'japanese-stablelm-base-alpha-7b'\n",
    "\n",
    "\"\"\"\n",
    "        input_ids: Optional[torch.LongTensor] = None,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple, CausalLMOutputWithPast]:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "22525010-7115-4825-924d-47d524ce00b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c61edc9f0ab346f697fe79935750766a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "JapaneseStableLMAlphaForCausalLM(\n",
       "  (transformer): JapaneseStableLMAlphaModel(\n",
       "    (embed_in): Embedding(65536, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x DecoderLayer(\n",
       "        (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=False)\n",
       "        (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): Attention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (dense): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): MLP(\n",
       "          (packed_input_proj): Linear(in_features=4096, out_features=22016, bias=False)\n",
       "          (out_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act): SiLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (embed_out): Linear(in_features=4096, out_features=65536, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(f'{model_vendor}/{model_name}', trust_remote_code=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5c7eadb3-63f6-4a49-a3b5-c8f9565078e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "2\n",
      "torch.Size([1, 32, 10, 128])\n"
     ]
    }
   ],
   "source": [
    "num_seq = 10\n",
    "n = num_seq\n",
    "# from config.json\n",
    "vocab_size = 65536\n",
    "hidden_size = 4096\n",
    "num_hidden_layers = 32\n",
    "num_attention_heads = 32\n",
    "\n",
    "past_kv      = torch.Tensor(size=(1, 32, num_seq, 128))\n",
    "hidden_state = torch.Tensor(size=(1, 32, num_seq, 128))\n",
    "#past_kv      = torch.Tensor(size=(1, 32, num_seq, num_seq))\n",
    "#hidden_state = torch.Tensor(size=(1, num_seq, 4096))\n",
    "\n",
    "past_key_values = tuple([(past_kv, hidden_state) for _ in range(32)])\n",
    "print(len(past_key_values))\n",
    "print(len(past_key_values[0]))\n",
    "print(past_key_values[0][0].shape)\n",
    "\n",
    "example_input = {\n",
    "    'input_ids'     : torch.tensor([[123]], dtype=torch.int),\n",
    "    'attention_mask': torch.tensor([[  1]], dtype=torch.int),\n",
    "    'position_ids'  : torch.tensor([[  0]], dtype=torch.int),\n",
    "    #'inputs_embeds': np.array([0], dtype=np.int32),\n",
    "    # input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\n",
    "    #'head_mask': torch.Tensor(size=(num_attention_heads,1,1,1,n)).to(torch.float32),\n",
    "\n",
    "    'past_key_values' : past_key_values,\n",
    "    #'past_key_values': torch.Tensor(size=(num_hidden_layers, 2, 1, num_attention_heads, num_seq, hidden_size // num_hidden_layers)).to(torch.float32),\n",
    "    #'past_key_values': torch.Tensor(size=(1, 2, 1, num_attention_heads, num_seq, hidden_size // num_hidden_layers)).to(torch.float32),\n",
    "    #  past_key_values [n][0|1][ 1, 32, seq_len, 128]\n",
    "\n",
    "    #'labels': np.zeros((1,100), dtype=np.int32),\n",
    "    'use_cache'           : torch.tensor(1, dtype=torch.int32),\n",
    "    'output_attentions'   : torch.tensor(0, dtype=torch.int32),\n",
    "    'output_hidden_states': torch.tensor(9, dtype=torch.int32),\n",
    "    'return_dict'         : torch.tensor(0, dtype=torch.int32),\n",
    "}\n",
    "\n",
    "#print(example_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8a4261b9-7833-4c64-bb1b-bbf350f62659",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nncf import compress_weights, CompressWeightsMode\n",
    "import nncf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1236d17d-fc34-4a72-b76b-3025ef38ce58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Model: 'Model21'\n",
      "inputs[\n",
      "<ConstOutput: names[input_ids] shape[?,?] type: i32>,\n",
      "<ConstOutput: names[attention_mask] shape[?,?] type: i32>,\n",
      "<ConstOutput: names[position_ids] shape[?,?] type: i32>,\n",
      "<ConstOutput: names[use_cache] shape[] type: i32>,\n",
      "<ConstOutput: names[output_attentions] shape[] type: i32>,\n",
      "<ConstOutput: names[output_hidden_states] shape[] type: i32>,\n",
      "<ConstOutput: names[return_dict] shape[] type: i32>\n",
      "]\n",
      "outputs[\n",
      "<ConstOutput: names[6430] shape[?,?,65536] type: f32>\n",
      "]>\n"
     ]
    }
   ],
   "source": [
    "ov_model = ov.convert_model(model, example_input=example_input)\n",
    "print(ov_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f7c3e186-dc37-436d-bb9e-b289ba23193c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:Statistics of the bitwidth distribution:\n",
      "+--------------+----------------------------+----------------------------+\n",
      "| Num bits (N) |        % all weight        |     % internal weights     |\n",
      "+==============+============================+============================+\n",
      "| 8            | -157705830400% (130 / 130) | -211392921600% (128 / 128) |\n",
      "+--------------+----------------------------+----------------------------+\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b335f0e610b943beac1b228c59f3244a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compressed_model = compress_weights(ov_model, mode=CompressWeightsMode.INT8)\n",
    "ov.save_model(compressed_model, 'openvino_model_int8_no_kv_out.xml')\n",
    "#ov.save_model(compressed_model, 'openvino_model_int8.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9b0255e1-3fbf-42d7-a105-6dd3e9b13d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:Statistics of the bitwidth distribution:\n",
      "+--------------+--------------+--------------------+\n",
      "| Num bits (N) | % all weight | % internal weights |\n",
      "+==============+==============+====================+\n",
      "+--------------+--------------+--------------------+\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Check 'bin_file' failed at src\\core\\src\\pass\\serialize.cpp:1226:\nCan't open bin file: \"openvino_model_int4asym.bin\"\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[99], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m compressed_model \u001b[38;5;241m=\u001b[39m compress_weights(ov_model, mode\u001b[38;5;241m=\u001b[39mCompressWeightsMode\u001b[38;5;241m.\u001b[39mINT4_ASYM)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mov\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompressed_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mopenvino_model_int4asym.xml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Check 'bin_file' failed at src\\core\\src\\pass\\serialize.cpp:1226:\nCan't open bin file: \"openvino_model_int4asym.bin\"\n"
     ]
    }
   ],
   "source": [
    "compressed_model = compress_weights(ov_model, mode=CompressWeightsMode.INT4_ASYM)\n",
    "ov.save_model(compressed_model, 'openvino_model_int4asym.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9a1d0f-1dee-4c06-b1ef-f26d83b1d198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from optimum.intel.openvino import OVModelForCausalLM\n",
    "#model = OVModelForCausalLM.from_pretrained(f'{model_vendor}/{model_name}', trust_remote_code=True, export=True, compile=False, load_in_8bit=False)\n",
    "\n",
    "\"\"\"\n",
    "<Model: 'Model0'\n",
    "inputs[\n",
    "<ConstOutput: names[input_ids] shape[?,?] type: i32>,\n",
    "<ConstOutput: names[attention_mask] shape[?,?] type: i32>,\n",
    "<ConstOutput: names[position_ids] shape[?,?] type: i32>,\n",
    "<ConstOutput: names[42] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[43] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[44] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[45] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[46] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[47] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[48] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[49] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[50] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[51] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[52] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[53] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[54] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[55] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[56] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[57] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[58] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[59] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[60] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[61] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[62] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[63] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[64] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[65] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[66] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[67] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[68] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[69] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[70] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[71] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[72] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[73] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[74] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[75] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[76] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[77] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[78] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[79] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[80] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[81] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[82] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[83] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[84] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[85] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[86] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[87] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[88] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[89] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[90] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[91] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[92] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[93] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[94] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[95] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[96] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[97] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[98] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[99] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[100] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[101] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[102] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[103] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[104] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[105] shape[?,32,?,128] type: f32>,\n",
    "<ConstOutput: names[use_cache] shape[?] type: i32>,\n",
    "<ConstOutput: names[output_attentions] shape[?] type: i32>,\n",
    "<ConstOutput: names[output_hidden_states] shape[?] type: i32>,\n",
    "<ConstOutput: names[return_dict] shape[?] type: i32>\n",
    "]\n",
    "outputs[\n",
    "<ConstOutput: names[7237, 172] shape[?,?,65536] type: f32>,\n",
    "<ConstOutput: names[285, hidden_states.1, 7172, 107] shape[?,?,4096] type: f32>,\n",
    "<ConstOutput: names[497, 7173, hidden_states.3, 499, 108] shape[?,?,4096] type: f32>,\n",
    "<ConstOutput: names[712, hidden_states.5, 714, 7174, 109] shape[?,?,4096] type: f32>,\n",
    "<ConstOutput: names[927, hidden_states.7, 7175, 929, 110] shape[?,?,4096] type: f32>,\n",
    "<ConstOutput: names[1142, hidden_states.9, 1144, 7176, 111] shape[?,?,4096] type: f32>,\n",
    "<ConstOutput: names[1357, hidden_states.11, 7177, 1359, 112] shape[?,?,4096] type: f32>,\n",
    "<ConstOutput: names[7178, 1572, hidden_states.13, 1574, 113] shape[?,?,4096] type: f32>,\n",
    "<ConstOutput: names[1787, hidden_states.15, 1789, 7179, 114] shape[?,?,4096] type: f32>,\n",
    "<ConstOutput: names[7180, 2002, 115, hidden_states.17, 2004] shape[?,?,4096] type: f32>,\n",
    "<ConstOutput: names[2217, hidden_states.19, 2219, 7181, 116] shape[?,?,4096] type: f32>,\n",
    "<ConstOutput: names[2432, 7182, hidden_states.21, 2434, 117] shape[?,?,4096] type: f32>,\n",
    "<ConstOutput: names[2647, 118, hidden_states.23, 2649, 7183] shape[?,?,4096] type: f32>,\n",
    "<ConstOutput: names[2862, hidden_states.25, 2864, 7184, 119] shape[?,?,4096] type: f32>,\n",
    "<ConstOutput: names[3077, hidden_states.27, 120, 7185, 3079] shape[?,?,4096] type: f32>,\n",
    "<ConstOutput: names[7186, 3292, hidden_states.29, 3294, 121] shape[?,?,4096] type: f32>,\n",
    "<ConstOutput: names[122, 7187, 3507, 3509, hidden_states.31] shape[?,?,4096] type: f32>,\n",
    "<ConstOutput: names[3722, hidden_states.33, 3724, 7188, 123] shape[?,?,4096] type: f32>,\n",
    "<ConstOutput: names[3937, hidden_states.35, 3939, 124, 7189] shape[?,?,4096] type: f32>,\n",
    "<ConstOutput: names[4152, hidden_states.37, 4154, 7190, 125] shape[?,?,4096] type: f32>,\n",
    "<ConstOutput: names[7191, 4367, hidden_states.39, 4369, 126] shape[?,?,4096] type: f32>,\n",
    "<ConstOutput: names[4582, hidden_states.41, 4584, 7192, 127] shape[?,?,4096] type: f32>,\n",
    "<ConstOutput: names[4797, hidden_states.43, 4799, 7193, 128] shape[?,?,4096] type: f32>,\n",
    "<ConstOutput: names[5012, 129, hidden_states.45, 5014, 7194] shape[?,?,4096] type: f32>,\n",
    "<ConstOutput: names[5227, 7195, hidden_states.47, 130, 5229] shape[?,?,4096] type: f32>,\n",
    "<ConstOutput: names[7196, 5442, hidden_states.49, 131, 5444] shape[?,?,4096] type: f32>,\n",
    "<ConstOutput: names[5657, hidden_states.51, 5659, 7197, 132] shape[?,?,4096] type: f32>,\n",
    "<ConstOutput: names[5872, hidden_states.53, 5874, 7198, 133] shape[?,?,4096] type: f32>,\n",
    "<ConstOutput: names[6087, hidden_states.55, 6089, 7199, 134] shape[?,?,4096] type: f32>,\n",
    "<ConstOutput: names[135, 6302, 6304, hidden_states.57, 7200] shape[?,?,4096] type: f32>,\n",
    "<ConstOutput: names[6517, hidden_states.59, 6519, 7201, 136] shape[?,?,4096] type: f32>,\n",
    "<ConstOutput: names[6732, hidden_states.61, 6734, 7202, 137] shape[?,?,4096] type: f32>,\n",
    "<ConstOutput: names[6947, hidden_states, 138, 6949, 7203] shape[?,?,4096] type: f32>,\n",
    "<ConstOutput: names[7169, 7171, 139] shape[?,?,4096] type: f32>,\n",
    "<ConstOutput: names[480, 466, 467, 500, 7204, 140] shape[?,32,?,?] type: f32>,\n",
    "<ConstOutput: names[681, 682, 7205, 141, 695, 715] shape[?,32,?,?] type: f32>,\n",
    "<ConstOutput: names[896, 897, 930, 910, 7206, 142] shape[?,32,?,?] type: f32>,\n",
    "<ConstOutput: names[7207, 143, 1111, 1112, 1125, 1145] shape[?,32,?,?] type: f32>,\n",
    "<ConstOutput: names[1340, 1326, 1327, 1360, 7208, 144] shape[?,32,?,?] type: f32>,\n",
    "<ConstOutput: names[1541, 1542, 1555, 1575, 7209, 145] shape[?,32,?,?] type: f32>,\n",
    "<ConstOutput: names[1770, 1756, 1757, 1790, 7210, 146] shape[?,32,?,?] type: f32>,\n",
    "<ConstOutput: names[1971, 1972, 1985, 2005, 7211, 147] shape[?,32,?,?] type: f32>,\n",
    "<ConstOutput: names[2186, 2187, 2200, 2220, 7212, 148] shape[?,32,?,?] type: f32>,\n",
    "<ConstOutput: names[2401, 2402, 2415, 2435, 7213, 149] shape[?,32,?,?] type: f32>,\n",
    "<ConstOutput: names[2630, 2616, 2617, 2650, 7214, 150] shape[?,32,?,?] type: f32>,\n",
    "<ConstOutput: names[2831, 2832, 2865, 2845, 7215, 151] shape[?,32,?,?] type: f32>,\n",
    "<ConstOutput: names[3060, 3046, 3047, 7216, 152, 3080] shape[?,32,?,?] type: f32>,\n",
    "<ConstOutput: names[3261, 3262, 3275, 7217, 153, 3295] shape[?,32,?,?] type: f32>,\n",
    "<ConstOutput: names[3490, 3476, 3477, 3510, 7218, 154] shape[?,32,?,?] type: f32>,\n",
    "<ConstOutput: names[7219, 155, 3691, 3692, 3705, 3725] shape[?,32,?,?] type: f32>,\n",
    "<ConstOutput: names[156, 3906, 3907, 3920, 3940, 7220] shape[?,32,?,?] type: f32>,\n",
    "<ConstOutput: names[4121, 4122, 4135, 4155, 157, 7221] shape[?,32,?,?] type: f32>,\n",
    "<ConstOutput: names[4350, 4336, 4337, 4370, 7222, 158] shape[?,32,?,?] type: f32>,\n",
    "<ConstOutput: names[4551, 4552, 4565, 7223, 4585, 159] shape[?,32,?,?] type: f32>,\n",
    "<ConstOutput: names[4766, 4767, 4780, 4800, 7224, 160] shape[?,32,?,?] type: f32>,\n",
    "<ConstOutput: names[4981, 4982, 4995, 5015, 7225, 161] shape[?,32,?,?] type: f32>,\n",
    "<ConstOutput: names[5196, 5197, 5210, 5230, 7226, 162] shape[?,32,?,?] type: f32>,\n",
    "<ConstOutput: names[5411, 5412, 5445, 7227, 163, 5425] shape[?,32,?,?] type: f32>,\n",
    "<ConstOutput: names[5626, 5627, 5640, 7228, 164, 5660] shape[?,32,?,?] type: f32>,\n",
    "<ConstOutput: names[5841, 5842, 5855, 5875, 7229, 165] shape[?,32,?,?] type: f32>,\n",
    "<ConstOutput: names[6070, 6056, 6057, 7230, 6090, 166] shape[?,32,?,?] type: f32>,\n",
    "<ConstOutput: names[6271, 6272, 6285, 6305, 7231, 167] shape[?,32,?,?] type: f32>,\n",
    "<ConstOutput: names[6486, 6487, 6520, 6500, 7232, 168] shape[?,32,?,?] type: f32>,\n",
    "<ConstOutput: names[169, 6701, 6702, 6715, 6735, 7233] shape[?,32,?,?] type: f32>,\n",
    "<ConstOutput: names[6916, 6917, 6930, 7234, 170, 6950] shape[?,32,?,?] type: f32>,\n",
    "<ConstOutput: names[7131, 7132, 7235, 171, 7145, 7165] shape[?,32,?,?] type: f32>\n",
    "]>\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
