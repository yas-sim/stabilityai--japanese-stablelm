{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c571bf74-b168-454b-a410-01028b79daf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:NNCF initialized successfully. Supported frameworks detected: torch, tensorflow, onnx, openvino\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoConfig, TextStreamer\n",
    "from optimum.intel import OVModelForCausalLM\n",
    "import openvino as ov\n",
    "\n",
    "model_id = 'stabilityai/japanese-stablelm-base-gamma-7b'\n",
    "model_vendor, model_name = model_id.split('/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd01057",
   "metadata": {},
   "source": [
    "## モデル変換 (OpenVINOモデル生成)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6305b02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This architecture : mistral was not validated, only :pegasus, bloom, opt, marian, blenderbot, blenderbot-small, gpt-bigcode, codegen, gpt-neo, gpt2, llama, gpt-neox, bart architectures were validated, use at your own risk.\n",
      "Framework not specified. Using pt to export the model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6f0735fb7fb42d28647a016b5cf5e30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the export variant default. Available variants are:\n",
      "    - default: The default ONNX variant.\n",
      "Using framework PyTorch: 2.2.1+cpu\n",
      "Overriding 1 configuration item(s)\n",
      "\t- use_cache -> True\n",
      "N:\\work\\venv-ov23.3\\lib\\site-packages\\transformers\\modeling_utils.py:4193: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
      "  warnings.warn(\n",
      "N:\\work\\venv-ov23.3\\lib\\site-packages\\transformers\\modeling_attn_mask_utils.py:114: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if (input_shape[-1] > 1 or self.sliding_window is not None) and self.is_causal:\n",
      "N:\\work\\venv-ov23.3\\lib\\site-packages\\optimum\\exporters\\onnx\\model_patcher.py:301: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if past_key_values_length > 0:\n",
      "N:\\work\\venv-ov23.3\\lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:120: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if seq_len > self.max_seq_len_cached:\n",
      "N:\\work\\venv-ov23.3\\lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:676: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if attention_mask.size() != (bsz, 1, q_len, kv_seq_len):\n",
      "Exception ignored in: <finalize object at 0x278c3d9bb20; dead>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\yas_s\\AppData\\Local\\Programs\\Python\\Python310\\lib\\weakref.py\", line 591, in __call__\n",
      "    return info.func(*info.args, **(info.kwargs or {}))\n",
      "  File \"C:\\Users\\yas_s\\AppData\\Local\\Programs\\Python\\Python310\\lib\\tempfile.py\", line 859, in _cleanup\n",
      "    cls._rmtree(name, ignore_errors=ignore_errors)\n",
      "  File \"C:\\Users\\yas_s\\AppData\\Local\\Programs\\Python\\Python310\\lib\\tempfile.py\", line 855, in _rmtree\n",
      "    _shutil.rmtree(name, onerror=onerror)\n",
      "  File \"C:\\Users\\yas_s\\AppData\\Local\\Programs\\Python\\Python310\\lib\\shutil.py\", line 750, in rmtree\n",
      "    return _rmtree_unsafe(path, onerror)\n",
      "  File \"C:\\Users\\yas_s\\AppData\\Local\\Programs\\Python\\Python310\\lib\\shutil.py\", line 620, in _rmtree_unsafe\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"C:\\Users\\yas_s\\AppData\\Local\\Programs\\Python\\Python310\\lib\\tempfile.py\", line 846, in onerror\n",
      "    cls._rmtree(path, ignore_errors=ignore_errors)\n",
      "  File \"C:\\Users\\yas_s\\AppData\\Local\\Programs\\Python\\Python310\\lib\\tempfile.py\", line 855, in _rmtree\n",
      "    _shutil.rmtree(name, onerror=onerror)\n",
      "  File \"C:\\Users\\yas_s\\AppData\\Local\\Programs\\Python\\Python310\\lib\\shutil.py\", line 750, in rmtree\n",
      "    return _rmtree_unsafe(path, onerror)\n",
      "  File \"C:\\Users\\yas_s\\AppData\\Local\\Programs\\Python\\Python310\\lib\\shutil.py\", line 601, in _rmtree_unsafe\n",
      "    onerror(os.scandir, path, sys.exc_info())\n",
      "  File \"C:\\Users\\yas_s\\AppData\\Local\\Programs\\Python\\Python310\\lib\\shutil.py\", line 598, in _rmtree_unsafe\n",
      "    with os.scandir(path) as scandir_it:\n",
      "NotADirectoryError: [WinError 267] ディレクトリ名が無効です。: 'C:\\\\Users\\\\yas_s\\\\AppData\\\\Local\\\\Temp\\\\tmpnvqcpk4c\\\\openvino_model.bin'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "173b2b2e42e940ed8a4e664b25e095dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:Statistics of the bitwidth distribution:\n",
      "+--------------+---------------------------+-----------------------------------+\n",
      "| Num bits (N) | % all parameters (layers) |    % ratio-defining parameters    |\n",
      "|              |                           |             (layers)              |\n",
      "+==============+===========================+===================================+\n",
      "| 8            | 23% (85 / 226)            | 20% (83 / 224)                    |\n",
      "+--------------+---------------------------+-----------------------------------+\n",
      "| 4            | 77% (141 / 226)           | 80% (141 / 224)                   |\n",
      "+--------------+---------------------------+-----------------------------------+\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aa243e3493e4e31b5a5e1b3de97f909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import nncf\n",
    "\n",
    "if not os.path.exists(f'{model_name}/INT4'):\n",
    "    ov_model=OVModelForCausalLM.from_pretrained(model_id, export=True, compile=False, load_in_8bit=False)\n",
    "    compressed_model = nncf.compress_weights(ov_model.half()._original_model, mode=nncf.CompressWeightsMode.INT4_ASYM, group_size=128, ratio=0.8)\n",
    "    os.makedirs(f'{model_name}/INT4')\n",
    "    ov.save_model(compressed_model, f'{model_name}/INT4/openvino_model.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf2101e",
   "metadata": {},
   "source": [
    "## OpenVINOモデルの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66b2b82c-5fe2-4b75-858e-76e82fd643c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compiling the model to CPU ...\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "ov_model = OVModelForCausalLM.from_pretrained(\n",
    "    model_id = f'{model_name}/INT4',\n",
    "    device='CPU',\n",
    "    ov_config={\"PERFORMANCE_HINT\": \"LATENCY\", \"NUM_STREAMS\": \"1\", \"CACHE_DIR\": \"./cache\"},\n",
    "    config=AutoConfig.from_pretrained(model_id)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e188e5b8-f5db-4397-a3ec-f4e7f0da2c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(user_query, inputs=\"\", sep=\"\\n\\n### \"):\n",
    "    sys_msg = \"以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。要求を適切に満たす応答を書きなさい。\"\n",
    "    p = sys_msg\n",
    "    roles = [\"指示\", \"応答\"]\n",
    "    msgs = [\": \\n\" + user_query, \": \"]\n",
    "    if inputs:\n",
    "        roles.insert(1, \"入力\")\n",
    "        msgs.insert(1, \": \\n\" + inputs)\n",
    "    for role, msg in zip(roles, msgs):\n",
    "        p += sep + role + msg\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "898808ef-bc2d-4573-8315-7f89a89e2a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer with prompt without any additional input\n",
    "user_inputs = {\n",
    "    \"user_query\": \"VR とはどのようなものですか？\",\n",
    "    \"inputs\": \"\"\n",
    "}\n",
    "prompt = build_prompt(**user_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1984265-1c76-4d34-a755-71645cd64cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Prompt:\n",
      "以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。要求を適切に満たす応答を書きなさい。\n",
      "\n",
      "### 指示: \n",
      "VR とはどのようなものですか？\n",
      "\n",
      "### 応答: \n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "バーチャルリアリティ（VR）シミュレーションは仮想世界へ人々を導く技術です。それらが現実の感触や経験を与えてくれます。これは通常コンピュータ上における視覚化・音声化した体験です。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'** Prompt:\\n{prompt}\\n-------------------------')\n",
    "input_tokens = tokenizer(prompt, return_tensors='pt', add_special_tokens=False)\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
    "response = ov_model.generate(**input_tokens, eos_token_id=tokenizer.eos_token_id, max_new_tokens=300, num_return_sequences=1, temperature=1.0, do_sample=True, top_k=5, top_p=0.90, repetition_penalty=1.2, streamer=streamer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5e62e8-f815-44b8-9c66-7d60d0374c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84474520-eb60-4db8-b676-2564f91fe77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !optimum-cli export openvino -m stabilityai/japanese-stablelm-base-gamma-7b --trust-remote-code --weight-format int4_asym_g64 --disable-stateful japanese-stablelm-base-gamma-7b/INT4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
