{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10a2eeb6-3f27-4e58-877a-661b03ae3611",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yshimur1\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n        input_ids: Optional[torch.LongTensor] = None,\\n        attention_mask: Optional[torch.FloatTensor] = None,\\n        position_ids: Optional[torch.LongTensor] = None,\\n        inputs_embeds: Optional[torch.FloatTensor] = None,\\n        head_mask: Optional[torch.FloatTensor] = None,\\n        past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\\n        labels: Optional[torch.LongTensor] = None,\\n        use_cache: Optional[bool] = None,\\n        output_attentions: Optional[bool] = None,\\n        output_hidden_states: Optional[bool] = None,\\n        return_dict: Optional[bool] = None,\\n    ) -> Union[Tuple, CausalLMOutputWithPast]:\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM\n",
    "import openvino as ov\n",
    "\n",
    "import torch\n",
    "\n",
    "model_vendor, model_name = 'stabilityai', 'japanese-stablelm-base-alpha-7b'\n",
    "\n",
    "\"\"\"\n",
    "        input_ids: Optional[torch.LongTensor] = None,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple, CausalLMOutputWithPast]:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22525010-7115-4825-924d-47d524ce00b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yshimur1\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "C:\\Users\\yshimur1\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8144d166964f407c86cd4244dbf7ce67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "JapaneseStableLMAlphaForCausalLM(\n",
       "  (transformer): JapaneseStableLMAlphaModel(\n",
       "    (embed_in): Embedding(65536, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x DecoderLayer(\n",
       "        (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=False)\n",
       "        (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): Attention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (dense): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): MLP(\n",
       "          (packed_input_proj): Linear(in_features=4096, out_features=22016, bias=False)\n",
       "          (out_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act): SiLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (embed_out): Linear(in_features=4096, out_features=65536, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(f'{model_vendor}/{model_name}', trust_remote_code=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4059894-77b3-4b6a-93c5-c07b6e227a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_seq = 100\n",
    "n = num_seq\n",
    "# from config.json\n",
    "vocab_size = 65536\n",
    "hidden_size = 4096\n",
    "num_hidden_layers = 32\n",
    "num_attention_heads = 32\n",
    "\n",
    "example_input = {\n",
    "    'input_ids': torch.tensor([[123]], dtype=torch.int),\n",
    "    'attention_mask': torch.tensor([[1]],dtype=torch.int),\n",
    "    'position_ids': torch.tensor([[0]], dtype=torch.int),\n",
    "    #'inputs_embeds': np.array([0], dtype=np.int32),\n",
    "    # input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\n",
    "    #'head_mask': torch.Tensor(size=(num_attention_heads,1,1,1,n)).to(torch.float32),\n",
    "\n",
    "    'past_key_values': torch.Tensor(size=(num_hidden_layers, 2, 1, num_attention_heads, num_seq, hidden_size // num_hidden_layers)).to(torch.float32),\n",
    "    #'past_key_values': torch.Tensor(size=(1, 2, 1, num_attention_heads, num_seq, hidden_size // num_hidden_layers)).to(torch.float32),\n",
    "    #  past_key_values [n][0|1][ 1, 32, seq_len, 128]\n",
    "\n",
    "    #'labels': np.zeros((1,100), dtype=np.int32),\n",
    "    'use_cache': torch.tensor([1], dtype=torch.int32),\n",
    "    'output_attentions': torch.tensor([32], dtype=torch.int32),\n",
    "    'output_hidden_states': torch.tensor([32], dtype=torch.int32),\n",
    "    'return_dict': torch.tensor([0], dtype=torch.int32),\n",
    "}\n",
    "\n",
    "#print(example_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a4261b9-7833-4c64-bb1b-bbf350f62659",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nncf import compress_weights, CompressWeightsMode\n",
    "import nncf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1236d17d-fc34-4a72-b76b-3025ef38ce58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Model: 'Model2'\n",
      "inputs[\n",
      "<ConstOutput: names[input_ids] shape[?,?] type: i32>,\n",
      "<ConstOutput: names[attention_mask] shape[?,?] type: i32>,\n",
      "<ConstOutput: names[position_ids] shape[?,?] type: i32>,\n",
      "<ConstOutput: names[past_key_values] shape[?,?,?,?,?,?] type: f32>,\n",
      "<ConstOutput: names[use_cache] shape[?] type: i32>,\n",
      "<ConstOutput: names[output_attentions] shape[?] type: i32>,\n",
      "<ConstOutput: names[output_hidden_states] shape[?] type: i32>,\n",
      "<ConstOutput: names[return_dict] shape[?] type: i32>\n",
      "]\n",
      "outputs[\n",
      "<ConstOutput: names[7270, 76] shape[?,?,65536] type: f32>,\n",
      "<ConstOutput: names[11, 189, hidden_states.1, 7205] shape[?,?,4096] type: f32>,\n",
      "<ConstOutput: names[437, hidden_states.3, 439, 7206, 12] shape[?,?,4096] type: f32>,\n",
      "<ConstOutput: names[655, 7207, 657, hidden_states.5, 13] shape[?,?,4096] type: f32>,\n",
      "<ConstOutput: names[873, hidden_states.7, 875, 7208, 14] shape[?,?,4096] type: f32>,\n",
      "<ConstOutput: names[1091, hidden_states.9, 1093, 7209, 15] shape[?,?,4096] type: f32>,\n",
      "<ConstOutput: names[1309, hidden_states.11, 1311, 7210, 16] shape[?,?,4096] type: f32>,\n",
      "<ConstOutput: names[1527, 7211, hidden_states.13, 1529, 17] shape[?,?,4096] type: f32>,\n",
      "<ConstOutput: names[1745, 1747, hidden_states.15, 7212, 18] shape[?,?,4096] type: f32>,\n",
      "<ConstOutput: names[1963, hidden_states.17, 1965, 7213, 19] shape[?,?,4096] type: f32>,\n",
      "<ConstOutput: names[20, 2181, hidden_states.19, 2183, 7214] shape[?,?,4096] type: f32>,\n",
      "<ConstOutput: names[2401, 2399, hidden_states.21, 7215, 21] shape[?,?,4096] type: f32>,\n",
      "<ConstOutput: names[22, 2617, hidden_states.23, 7216, 2619] shape[?,?,4096] type: f32>,\n",
      "<ConstOutput: names[2835, hidden_states.25, 2837, 7217, 23] shape[?,?,4096] type: f32>,\n",
      "<ConstOutput: names[3053, hidden_states.27, 3055, 7218, 24] shape[?,?,4096] type: f32>,\n",
      "<ConstOutput: names[3271, hidden_states.29, 7219, 3273, 25] shape[?,?,4096] type: f32>,\n",
      "<ConstOutput: names[3489, hidden_states.31, 3491, 7220, 26] shape[?,?,4096] type: f32>,\n",
      "<ConstOutput: names[27, 3707, 3709, hidden_states.33, 7221] shape[?,?,4096] type: f32>,\n",
      "<ConstOutput: names[3925, hidden_states.35, 3927, 7222, 28] shape[?,?,4096] type: f32>,\n",
      "<ConstOutput: names[4143, hidden_states.37, 4145, 7223, 29] shape[?,?,4096] type: f32>,\n",
      "<ConstOutput: names[4361, 7224, hidden_states.39, 4363, 30] shape[?,?,4096] type: f32>,\n",
      "<ConstOutput: names[4579, 7225, 4581, hidden_states.41, 31] shape[?,?,4096] type: f32>,\n",
      "<ConstOutput: names[32, 4797, hidden_states.43, 4799, 7226] shape[?,?,4096] type: f32>,\n",
      "<ConstOutput: names[5015, hidden_states.45, 5017, 7227, 33] shape[?,?,4096] type: f32>,\n",
      "<ConstOutput: names[5233, hidden_states.47, 7228, 5235, 34] shape[?,?,4096] type: f32>,\n",
      "<ConstOutput: names[5451, 35, hidden_states.49, 5453, 7229] shape[?,?,4096] type: f32>,\n",
      "<ConstOutput: names[7230, 5669, hidden_states.51, 5671, 36] shape[?,?,4096] type: f32>,\n",
      "<ConstOutput: names[5887, hidden_states.53, 5889, 7231, 37] shape[?,?,4096] type: f32>,\n",
      "<ConstOutput: names[6105, hidden_states.55, 7232, 6107, 38] shape[?,?,4096] type: f32>,\n",
      "<ConstOutput: names[6323, 7233, hidden_states.57, 6325, 39] shape[?,?,4096] type: f32>,\n",
      "<ConstOutput: names[7234, 6541, hidden_states.59, 40, 6543] shape[?,?,4096] type: f32>,\n",
      "<ConstOutput: names[6759, hidden_states.61, 6761, 7235, 41] shape[?,?,4096] type: f32>,\n",
      "<ConstOutput: names[6977, 6979, hidden_states, 7236, 42] shape[?,?,4096] type: f32>,\n",
      "<ConstOutput: names[7202, 43, 7204] shape[?,?,4096] type: f32>,\n",
      "<ConstOutput: names[44, 406, 407, 420, 440, 7237] shape[?,32,?,?] type: f32>,\n",
      "<ConstOutput: names[7238, 624, 625, 658, 638, 45] shape[?,32,?,?] type: f32>,\n",
      "<ConstOutput: names[842, 843, 856, 876, 7239, 46] shape[?,32,?,?] type: f32>,\n",
      "<ConstOutput: names[1060, 1061, 1074, 1094, 7240, 47] shape[?,32,?,?] type: f32>,\n",
      "<ConstOutput: names[1278, 1279, 1312, 1292, 48, 7241] shape[?,32,?,?] type: f32>,\n",
      "<ConstOutput: names[1496, 1497, 1510, 1530, 7242, 49] shape[?,32,?,?] type: f32>,\n",
      "<ConstOutput: names[1714, 1715, 1728, 1748, 7243, 50] shape[?,32,?,?] type: f32>,\n",
      "<ConstOutput: names[1932, 1933, 1946, 1966, 7244, 51] shape[?,32,?,?] type: f32>,\n",
      "<ConstOutput: names[2150, 2151, 2164, 52, 2184, 7245] shape[?,32,?,?] type: f32>,\n",
      "<ConstOutput: names[2382, 2368, 2369, 2402, 53, 7246] shape[?,32,?,?] type: f32>,\n",
      "<ConstOutput: names[2586, 2587, 7247, 2600, 2620, 54] shape[?,32,?,?] type: f32>,\n",
      "<ConstOutput: names[2804, 2805, 7248, 2818, 2838, 55] shape[?,32,?,?] type: f32>,\n",
      "<ConstOutput: names[56, 3022, 3023, 3056, 3036, 7249] shape[?,32,?,?] type: f32>,\n",
      "<ConstOutput: names[3240, 3241, 3254, 7250, 3274, 57] shape[?,32,?,?] type: f32>,\n",
      "<ConstOutput: names[3472, 3458, 3459, 3492, 7251, 58] shape[?,32,?,?] type: f32>,\n",
      "<ConstOutput: names[3690, 3676, 3677, 3710, 7252, 59] shape[?,32,?,?] type: f32>,\n",
      "<ConstOutput: names[3928, 60, 3894, 3895, 7253, 3908] shape[?,32,?,?] type: f32>,\n",
      "<ConstOutput: names[7254, 4112, 4113, 4126, 4146, 61] shape[?,32,?,?] type: f32>,\n",
      "<ConstOutput: names[4330, 4331, 4344, 4364, 7255, 62] shape[?,32,?,?] type: f32>,\n",
      "<ConstOutput: names[63, 4548, 4549, 4562, 4582, 7256] shape[?,32,?,?] type: f32>,\n",
      "<ConstOutput: names[4766, 4767, 4780, 7257, 4800, 64] shape[?,32,?,?] type: f32>,\n",
      "<ConstOutput: names[4984, 4985, 4998, 5018, 7258, 65] shape[?,32,?,?] type: f32>,\n",
      "<ConstOutput: names[5202, 5203, 5236, 5216, 7259, 66] shape[?,32,?,?] type: f32>,\n",
      "<ConstOutput: names[5420, 5421, 5434, 5454, 7260, 67] shape[?,32,?,?] type: f32>,\n",
      "<ConstOutput: names[5638, 5639, 5652, 7261, 5672, 68] shape[?,32,?,?] type: f32>,\n",
      "<ConstOutput: names[5856, 5857, 69, 5870, 5890, 7262] shape[?,32,?,?] type: f32>,\n",
      "<ConstOutput: names[6108, 6074, 6075, 6088, 7263, 70] shape[?,32,?,?] type: f32>,\n",
      "<ConstOutput: names[6326, 7264, 6292, 6293, 6306, 71] shape[?,32,?,?] type: f32>,\n",
      "<ConstOutput: names[6510, 6511, 6524, 6544, 72, 7265] shape[?,32,?,?] type: f32>,\n",
      "<ConstOutput: names[6742, 7266, 6728, 6729, 6762, 73] shape[?,32,?,?] type: f32>,\n",
      "<ConstOutput: names[6960, 74, 6946, 6947, 6980, 7267] shape[?,32,?,?] type: f32>,\n",
      "<ConstOutput: names[7164, 7165, 7198, 7178, 7268, 75] shape[?,32,?,?] type: f32>\n",
      "]>\n"
     ]
    }
   ],
   "source": [
    "ov_model = ov.convert_model(model, example_input=example_input)\n",
    "print(ov_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7c3e186-dc37-436d-bb9e-b289ba23193c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:Statistics of the bitwidth distribution:\n",
      "+--------------+---------------------------+-----------------------------------+\n",
      "| Num bits (N) | % all parameters (layers) |    % ratio-defining parameters    |\n",
      "|              |                           |             (layers)              |\n",
      "+==============+===========================+===================================+\n",
      "| 8            | 8% (2 / 130)              | 0% (0 / 128)                      |\n",
      "+--------------+---------------------------+-----------------------------------+\n",
      "| 4            | 92% (128 / 130)           | 100% (128 / 128)                  |\n",
      "+--------------+---------------------------+-----------------------------------+\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f06433320b5045b3b6c7aaea311cda3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#compressed_model = compress_weights(ov_model, mode=CompressWeightsMode.INT8_SYM)\n",
    "compressed_model = compress_weights(ov_model, mode=CompressWeightsMode.INT4_ASYM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b0255e1-3fbf-42d7-a105-6dd3e9b13d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ov.save_model(compressed_model, 'openvino_model_int4asym.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9a1d0f-1dee-4c06-b1ef-f26d83b1d198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from optimum.intel.openvino import OVModelForCausalLM\n",
    "#model = OVModelForCausalLM.from_pretrained(f'{model_vendor}/{model_name}', trust_remote_code=True, export=True, compile=False, load_in_8bit=False)\n",
    "\n",
    "\"\"\"\n",
    "<Model: 'Model0'\n",
    "inputs[\n",
    "<ConstOutput: names[input_ids] shape[?,?] type: i32>,\n",
    "<ConstOutput: names[attention_mask] shape[?,?] type: f32>,\n",
    "<ConstOutput: names[position_ids] shape[?,?] type: i32>,\n",
    "<ConstOutput: names[head_mask, 146, head_mask.3] shape[?,?,?,?,?] type: f32>,\n",
    "<ConstOutput: names[use_cache] shape[?] type: i32>,\n",
    "<ConstOutput: names[output_attentions] shape[?] type: i32>,\n",
    "<ConstOutput: names[output_hidden_states] shape[?] type: i32>,\n",
    "<ConstOutput: names[return_dict] shape[?] type: i32>\n",
    "]\n",
    "outputs[\n",
    "<ConstOutput: names[6522] shape[?,?,65536] type: f32>\n",
    "]>\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
